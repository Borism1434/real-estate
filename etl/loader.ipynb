{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0555fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.py\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Config dict for connection\n",
    "DB_CONFIG = {\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\"),\n",
    "    \"database\": os.getenv(\"DB_NAME\"),\n",
    "}\n",
    "\n",
    "# --- SQLAlchemy Engine ---\n",
    "def get_engine():\n",
    "    conn_str = (\n",
    "        f\"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@\"\n",
    "        f\"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    return create_engine(conn_str)\n",
    "\n",
    "# --- psycopg2 raw connection (for copy_expert) ---\n",
    "def get_psycopg2_conn():\n",
    "    return psycopg2.connect(\n",
    "        dbname=DB_CONFIG[\"database\"],\n",
    "        user=DB_CONFIG[\"user\"],\n",
    "        password=DB_CONFIG[\"password\"],\n",
    "        host=DB_CONFIG[\"host\"],\n",
    "        port=DB_CONFIG[\"port\"]\n",
    "    )\n",
    "\n",
    "# --- Read query into DataFrame ---\n",
    "def run_query(query: str) -> pd.DataFrame:\n",
    "    engine = get_engine()\n",
    "    with engine.connect() as conn:\n",
    "        return pd.read_sql(query, conn)\n",
    "\n",
    "# --- Execute raw SQL (DDL or DML) ---\n",
    "def execute_sql(sql: str):\n",
    "    engine = get_engine()\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(sql))\n",
    "\n",
    "# --- Load a DataFrame to a PostgreSQL table (fast) ---\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def load_dataframe(\n",
    "    df: pd.DataFrame = None,\n",
    "    table_name: str = \"\",\n",
    "    schema: str = \"src\",\n",
    "    method: str = \"replace\",\n",
    "    data_dir: str = None,\n",
    "    load_mode: str = \"recent\"  # or \"all\"\n",
    "):\n",
    "    import glob\n",
    "    import re\n",
    "\n",
    "    # --- Helper to clean column names before load ---\n",
    "    def clean_column_names(df):\n",
    "        df.columns = (\n",
    "            df.columns\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.lower()\n",
    "            .str.replace(r\"[^\\w]+\", \"_\", regex=True)   # replace +, spaces, etc. with underscore\n",
    "            .str.replace(r\"_+\", \"_\", regex=True)       # collapse multiple underscores\n",
    "            .str.strip(\"_\")                            # trim leading/trailing underscores\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    # --- Load files if df not provided ---\n",
    "    if df is None and data_dir:\n",
    "        file_patterns = [\"*.csv\", \"*.CSV\", \"*.xlsx\", \"*.parquet\"]\n",
    "        files = []\n",
    "        for pattern in file_patterns:\n",
    "            files.extend(glob.glob(os.path.join(data_dir, pattern)))\n",
    "\n",
    "        if not files:\n",
    "            print(\"‚ùå No data files (.csv, .xlsx, .parquet) found in directory.\")\n",
    "            return\n",
    "\n",
    "        # Sort by modified time (newest first)\n",
    "        files.sort(key=os.path.getmtime, reverse=True)\n",
    "\n",
    "        if load_mode == \"recent\":\n",
    "            files = [files[0]]  # only most recent file\n",
    "\n",
    "        dfs = []\n",
    "        for f in files:\n",
    "            try:\n",
    "                if f.endswith((\".csv\", \".CSV\")):\n",
    "                    dfs.append(pd.read_csv(f))\n",
    "                elif f.endswith(\".xlsx\"):\n",
    "                    dfs.append(pd.read_excel(f))\n",
    "                elif f.endswith(\".parquet\"):\n",
    "                    dfs.append(pd.read_parquet(f))\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Unsupported file format skipped: {f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to read {f}: {e}\")\n",
    "\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # --- Exit early if still no data ---\n",
    "    if df is None or df.empty:\n",
    "        print(\"‚ö†Ô∏è No valid data to load.\")\n",
    "        return\n",
    "\n",
    "    # --- Clean column names (to handle +, spaces, etc.) ---\n",
    "    df = clean_column_names(df)\n",
    "\n",
    "    # --- Replace NaN with None for Postgres ---\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # --- Load into Postgres ---\n",
    "    with get_psycopg2_conn() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            if method == \"replace\":\n",
    "                cur.execute(f\"TRUNCATE TABLE {schema}.{table_name};\")\n",
    "\n",
    "            buffer = StringIO()\n",
    "            df.to_csv(buffer, index=False, header=False)\n",
    "            buffer.seek(0)\n",
    "\n",
    "            copy_sql = f\"\"\"\n",
    "                COPY {schema}.{table_name} ({', '.join(df.columns)})\n",
    "                FROM STDIN WITH CSV\n",
    "            \"\"\"\n",
    "            try:\n",
    "                cur.copy_expert(copy_sql, buffer)\n",
    "                conn.commit()\n",
    "                print(f\"‚úÖ Loaded {len(df)} rows into {schema}.{table_name}\")\n",
    "            except Exception as e:\n",
    "                conn.rollback()\n",
    "                print(\"‚ùå Load failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a9bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 3 rows into src.test_real_estate\n",
      "‚úÖ Loaded data:\n",
      "   bedrooms  total_bathrooms  last_sale_amount last_sale_date\n",
      "0       3.0              2.5          300000.0     2021-07-01\n",
      "1       2.0              1.0               NaN     2020-05-12\n",
      "2       NaN              1.5          150000.0           None\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Upload\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # ‚úÖ Sample dummy DataFrame\n",
    "#     import pandas as pd\n",
    "\n",
    "#     df_test = pd.DataFrame({\n",
    "#         \"bedrooms\": [3, 2, None],\n",
    "#         \"total_bathrooms\": [2.5, 1.0, 1.5],\n",
    "#         \"last_sale_amount\": [300000, None, 150000],\n",
    "#         \"last_sale_date\": [\"2021-07-01\", \"2020-05-12\", None]\n",
    "#     })\n",
    "\n",
    "#     # üß™ Make sure your target table exists first\n",
    "#     # You can create it manually or via SQL below:\n",
    "#     create_sql = \"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS src.test_real_estate (\n",
    "#         bedrooms NUMERIC,\n",
    "#         total_bathrooms NUMERIC,\n",
    "#         last_sale_amount NUMERIC,\n",
    "#         last_sale_date DATE\n",
    "#     );\n",
    "#     \"\"\"\n",
    "#     execute_sql(create_sql)\n",
    "\n",
    "#     # üöÄ Run loader test\n",
    "#     load_dataframe(df_test, table_name=\"test_real_estate\", schema=\"src\", method=\"replace\")\n",
    "\n",
    "#     # ‚úÖ Query to verify insert\n",
    "#     result = run_query(\"SELECT * FROM src.test_real_estate;\")\n",
    "#     print(\"‚úÖ Loaded data:\")\n",
    "#     print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
